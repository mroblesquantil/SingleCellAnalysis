{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LibrerÃ­as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/GMM /')\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_distancias = '../data/correlaciones_10x/correlaciones.pickle'\n",
    "path_datos = '../data/10X_PBMC_select_2100.h5'\n",
    "path_out = '../data/correlaciones_10x/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_distancias, 'rb') as f:\n",
    "    correlaciones_hl = pickle.load(f)\n",
    "\n",
    "with h5py.File(path_datos) as f:\n",
    "    #X = np.array(f['X'])\n",
    "    y = np.array(f['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(y) == len(correlaciones_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.heatmap(correlaciones_hl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kMST(distance_matrix, correlations = True, k = None, threshold = 1e-5):\n",
    "    if k is None:\n",
    "        N = np.log(len(distance_matrix))\n",
    "        k = int(np.floor(N))\n",
    "    \n",
    "    print(f'k = {k}')\n",
    "    grafo = nx.Graph()\n",
    "    nodos = range(len(distance_matrix))\n",
    "\n",
    "    # Crear nodo inicial\n",
    "    grafo.add_nodes_from(nodos)\n",
    "\n",
    "    for i in range(len(distance_matrix)):\n",
    "        for j in range(i + 1, len(distance_matrix[i])):\n",
    "            peso = distance_matrix[i][j]\n",
    "            if peso > threshold:\n",
    "                # para MST necesito el inverso de las correlaciones\n",
    "                if correlations:\n",
    "                    grafo.add_edge(i, j, weight=1-peso)\n",
    "                else:\n",
    "                    grafo.add_edge(i, j, weight=peso)\n",
    "\n",
    "\n",
    "    print(f'---> Number of edges: {grafo.number_of_edges()}')\n",
    "\n",
    "    mst_antes = None\n",
    "    # Creamos los MSTs\n",
    "    for iter in range(k):\n",
    "        mst_new = nx.minimum_spanning_tree(grafo)\n",
    "\n",
    "        edges_to_remove = list(mst_new.edges)\n",
    "        grafo.remove_edges_from(edges_to_remove)\n",
    "        print(f'---> {iter}. Number of edges: {grafo.number_of_edges()}')\n",
    "\n",
    "        if mst_antes is None:\n",
    "            mst_antes = mst_new.copy()\n",
    "        else:\n",
    "            mst_new.add_edges_from(list(mst_antes.edges()))\n",
    "            mst_antes = mst_new.copy()\n",
    "\n",
    "    return mst_antes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 7\n",
      "---> Number of edges: 897235\n",
      "---> 0. Number of edges: 895136\n",
      "---> 1. Number of edges: 893037\n",
      "---> 2. Number of edges: 890938\n",
      "---> 3. Number of edges: 888839\n",
      "---> 4. Number of edges: 886740\n",
      "---> 5. Number of edges: 884641\n",
      "---> 6. Number of edges: 882542\n"
     ]
    }
   ],
   "source": [
    "union_graph_msts = create_kMST(correlaciones_hl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14693"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_graph_msts.number_of_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_out + 'grafo_kMST_correlaciones.pickle', 'wb') as f:\n",
    "    pickle.dump(union_graph_msts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Louvain sobre el kMST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10X PBMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/correlaciones_10x/grafo_kMST_correlaciones.pickle', 'rb') as f:\n",
    "    mst = pickle.load(f) \n",
    "    \n",
    "with h5py.File('../data/10X_PBMC_select_2100.h5') as f:\n",
    "    X = np.array(f['X'])\n",
    "    y = np.array(f['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mst.number_of_nodes() == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 6, 3, ..., 5, 1, 1])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particiones = nx.community.louvain_communities(mst, seed=123)\n",
    "\n",
    "diccionario = {}\n",
    "for i, conjunto in enumerate(particiones):\n",
    "    for elemento in conjunto:\n",
    "        diccionario[elemento] = i \n",
    "\n",
    "max_elemento = max(max(particiones, key = max), default=-1)\n",
    "clusters = np.array([diccionario.get(i, -1) for i in range(max_elemento + 1)])\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(clusters)), len(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.744. NMI: 0.682. ARI: 0.68\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_mutual_info_score\n",
    "\n",
    "acc = round(cluster_acc(clusters,y), 3)\n",
    "nmi = round(normalized_mutual_info_score(clusters,y), 3)\n",
    "ari = round(adjusted_mutual_info_score(clusters,y), 3)\n",
    "\n",
    "print(f'ACC: {acc}. NMI: {nmi}. ARI: {ari}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Human Liver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/correlaciones_human_liver/grafo_kMST_correlaciones.pickle', 'rb') as f:\n",
    "    mst = pickle.load(f) \n",
    "    \n",
    "with h5py.File('../data/HumanLiver_counts_top5000.h5') as f:\n",
    "    X = np.array(f['X'])\n",
    "    y = np.array(f['Y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert mst.number_of_nodes() == len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 12, 11, ..., 12,  8, 10])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "particiones = nx.community.louvain_communities(mst, seed=123)\n",
    "\n",
    "diccionario = {}\n",
    "for i, conjunto in enumerate(particiones):\n",
    "    for elemento in conjunto:\n",
    "        diccionario[elemento] = i \n",
    "\n",
    "max_elemento = max(max(particiones, key = max), default=-1)\n",
    "clusters = np.array([diccionario.get(i, -1) for i in range(max_elemento + 1)])\n",
    "clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(clusters)), len(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.715. NMI: 0.778. ARI: 0.777\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_mutual_info_score\n",
    "\n",
    "acc = round(cluster_acc(clusters,y), 3)\n",
    "nmi = round(normalized_mutual_info_score(clusters,y), 3)\n",
    "ari = round(adjusted_mutual_info_score(clusters,y), 3)\n",
    "\n",
    "print(f'ACC: {acc}. NMI: {nmi}. ARI: {ari}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_scRNA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
